p8105_hw2_zz3167
================
Zhiyi Zhu
2023-09-29

``` r
library(tidyverse)
library(readxl)
library(dplyr)
```

## Problem 1

### Clean the data in pols-month.csv

``` r
pols_df = 
  read_csv("data/pols-month.csv") |>
  janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.numeric(year)
  ) |>
  mutate(
    month = case_match(
      month,
      "01" ~ "January",
      "02" ~ "Febuary",
      "03" ~ "March",
      "04" ~ "Aprial",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July",
      "08" ~ "August",
      "09" ~ "September",
      "10" ~ "October",
      "11" ~ "November",
      "12" ~ "December" )
  ) |>
  mutate(
    president = case_match(
      prez_gop,
      1 ~ "gop",
      0 ~ "dem" )
  ) |>
  select(-prez_gop, -prez_dem, -day)
```

### Clean the data in snp.csv

``` r
snp_df = 
  read_csv("data/snp.csv") |>
  janitor::clean_names() |>
  mutate(
    date = as.Date(date, format = "%m/%d/%y"),
    date = as.Date(ifelse(date > Sys.Date(),
                           format(date, "19%y-%m-%d"),
                           format(date)))
  ) |>
  separate(date, into = c("year", "month", "day"), sep = "-") |>
  mutate(
    year = as.numeric(year)
  ) |>
  select(-day) |>
  arrange(year,month) |>
  mutate(
     month = case_match(
      month,
      "01" ~ "January",
      "02" ~ "Febuary",
      "03" ~ "March",
      "04" ~ "Aprial",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July",
      "08" ~ "August",
      "09" ~ "September",
      "10" ~ "October",
      "11" ~ "November",
      "12" ~ "December" )
   ) |>
  select(year, month, everything())
```

### Clean the the data in unemployment.csv

``` r
unem_df = 
  read_csv("data/unemployment.csv") |>
  janitor::clean_names() |>
  pivot_longer(jan:dec,
               names_to = "month",
               values_to = "unemployment percentage"
               )|>
  mutate(
    month = case_match(
      month,
      "jan" ~ "January",
      "feb" ~ "Febuary",
      "mar" ~ "March",
      "apr" ~ "April", 
      "may" ~ "May",
      "jun" ~ "June",
      "jul" ~ "July",
      "aug" ~ "August",
      "sep" ~ "September",
      "oct" ~ "October",
      "nov" ~ "November",
      "dec" ~ "December")
  )
```

### Join the datasets by merging snp into pols, and merging unemployment into the result

``` r
snp_pols_df = 
  left_join(pols_df, snp_df, by = c("year", "month"))

merged_df = 
  left_join(snp_pols_df, unem_df, by = c("year", "month"))
```

### Write a short paragraph about these datasets

- The dataset `pols_df` has 822 rows(observations) and 9
  columns(variables). The range of the year is from January 1947 to
  June 2015. The key variables are year, month, gov_gop, sen_gop,
  rep_gop, gov_dem, sen_dem, rep_dem, president.
- The dataset `snp_df` has 787 rows(observations) and 3
  columns(variables). The range of years is from January 1950 to
  July 2015. The key variables are year, month, close.
- The dataset `unem_df` has 816 rows(observations) and 3
  columns(variables). The range of years is from January 1948 to
  June 2015. The key variables are year, month, unemployment percentage.
- The resulting dataset `merged_df` has 822 rows(observations) and 11
  columns(variables). The range of years is from January 1947 to
  June 2015. The names of key variables are year, month, gov_gop,
  sen_gop, rep_gop, gov_dem, sen_dem, rep_dem, president, close,
  unemployment percentage.

## Problem 2

### Read and clean the Mr. Trash Wheel sheet

``` r
MrTrash_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel", range = "A2:N586")|>
  janitor::clean_names()|>
  separate(date, into = c("year", "month0", "day"), sep = "-")|>
  select(-month0)|>
  relocate(year, .before = month)
```

### Update the data to include a new homes_powered variable

``` r
MrTrash_df = 
  mutate(
    MrTrash_df,
    homes_powered = weight_tons*500/30
      )
```

### Use a similar process to work with Professor Trash Wheel and Gwynnda

``` r
ProfessorTrash_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel", range = "A2:M108")|>
  janitor::clean_names()|>
  separate(date, into = c("year", "month0", "day"), sep = "-")|>
  select(-month0)|>
  relocate(year, .before = month)|>
  mutate(homes_powered = weight_tons*500/30)
```

``` r
Gwynnda_df = 
  read_excel("data/202309 Trash Wheel Collection Data.xlsx",sheet = "Gwynnda Trash Wheel", range = "A2:L157")|>
  janitor::clean_names()|>
  separate(date, into = c("year", "month0", "day"), sep = "-")|>
  select(-month0)|>
  relocate(year, .before = month)|>
  mutate(homes_powered = weight_tons*500/30)
```

### Add an additional variable to all datasets to keep track

``` r
MrTrash_df = mutate(MrTrash_df, track = "Mr Trash wheel")
ProfessorTrash_df = mutate(ProfessorTrash_df, track = "Professor Trash Wheel")
Gwynnda_df = mutate(Gwynnda_df, track = "Gwynnda Trash wheel")
```

### Combine the two dataset with Mr. Trash Wheel and do some adjustment

``` r
Combine_trash = 
  bind_rows(MrTrash_df, ProfessorTrash_df, Gwynnda_df)|>
  relocate(track, .before = year)|>
  relocate(homes_powered, .after = plastic_bags)
```

### Write a paragraph about these data

- The dataset `MrTrash_df` has 584 rows(observations) and 15
  columns(variables). The key variables are dumpster, year, month, day,
  weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
  cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls,
  homes_powered, track.
- The dataset `ProfessorTrash_df` has 106 rows(observations) and 14
  columns(variables). The key variables are dumpster, year, month, day,
  weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
  cigarette_butts, glass_bottles, plastic_bags, wrappers, homes_powered,
  track.
- The dataset `Gwynnda_df` has 155 rows(observations) and 13
  columns(variables). The key variables are dumpster, year, month, day,
  weight_tons, volume_cubic_yards, plastic_bottles, polystyrene,
  cigarette_butts, plastic_bags, wrappers, homes_powered, track.
- The resulting dataset `Combine_trash` has 845 rows(observations) and
  15 columns(variables). The key variables are dumpster, track, year,
  month, day, weight_tons, volume_cubic_yards, plastic_bottles,
  polystyrene, cigarette_butts, glass_bottles, plastic_bags,
  homes_powered, wrappers, sports_balls.
- The total weight of trash collected by Professor Trash Wheel is 216.26
  tons. The total number of cigarette butts collected by Gwynnda in July
  of 2021 is 1.63^{4}.

## Problem 3

### Import, clean, and tidy the dataset of baseline demographics

``` r
baseline_df = 
  read_csv("data_mci/MCI_baseline.csv", skip = 1) |>
  janitor::clean_names()|>
  mutate(
    sex = case_match(
      sex,
      1 ~ "male",
      0 ~ "female")
  )|>
  mutate(
    apoe4 = case_match(
      apoe4,
      1 ~ "APOE4 carrier", 
      0 ~ "APOE4 non-carrier")
  )
  
standard_baseline_df = filter(baseline_df, age_at_onset > current_age | age_at_onset == '.')
```

### Discuss important steps in the import process

- We use read_csv function to import data, then we use skip = 1 function
  to skip the first row cause it’s the given notes help us to understand
  what the numbers in each columns represent.
- We use mutate function to change the sex and apoe4 values according to
  the explanation in row 1.
- We use filter function to remove any participants who do not meet the
  stated inclusion criteria.

### Discuss relevant features of the dataset

- Of the initial 483 participants enrolled, 479 met the required
  inclusion criteria, but 4 had MCI prior to recruitment and did not
  meet the recruitment criteria.
- Among participants who meet the criteria, 93 developed MCI.
- The average baseline age is 65.0286013.
- 30% women in the study are APOE4 carriers.

### Import, clean, and tidy the dataset of longitudinally observed biomarker values

``` r
amyloid_df = 
  read_csv("data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names()|>
  rename(id = study_id)
```

### Comment on the steps

- We use read_csv function to import data, then we use skip = 1 function
  to skip the first row which is the explanation.
- We use rename function to change the “study_id” to “id” in order to
  easily combine or compare the two dataset.

### Discuss relevant features of the dataset

- There are 487 rows(observations) and 6 columns(variables) in the
  dataset `amyloid_df`. The names of variables are: id, baseline,
  time_2, time_4, time_6, time_8.

### Check whether some participants appear in only the baseline or amyloid datasets

``` r
only_baseline = anti_join(standard_baseline_df, amyloid_df, by = "id")
only_amyloid = anti_join(amyloid_df, standard_baseline_df, by = "id")
```

- There are 8 participants only appear in baseline dataset, their ids
  are 14, 49, 92, 179, 268, 304, 389, 412.
- There are 16 participants only appear in amyloid dataset, their ids
  are 72, 234, 283, 380, 484, 485, 486, 487, 488, 489, 490, 491, 492,
  493, 494, 495.

### Combine the demographic and biomarker dataset

``` r
combine_df = inner_join(standard_baseline_df, amyloid_df, by = "id")
```

### Briefly describe the resulting dataset

- There are 471 participants appear in both dataset. 266 of them are
  male, and 30.08% male are APOE4 carriers. 205 of them are female, and
  30.24% female are APOE4 carriers.

### Export combined dataset as CSV

``` r
write_csv(combine_df, "data_mci/combine_dataset.csv")
```
